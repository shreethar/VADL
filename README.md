# ğŸ¥ VADL â€” Video Anomaly Detection & Localization

VADL is an AI-powered framework for detecting and localizing anomalies in video data.  
It leverages deep learning models to learn normal spatiotemporal patterns and identify deviations in unseen footage.

---

## ğŸ“ Project Structure

```

VADL/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing.py     # Data preprocessing (frame extraction, normalization, etc.)
â”‚   â”œâ”€â”€ train.py             # Model training
â”‚   â”œâ”€â”€ evaluate.py          # Model evaluation on validation/test sets
â”‚   â”œâ”€â”€ convertonnx.py       # Converts trained model to ONNX format for deployment
â”‚   â”œâ”€â”€ infer.py             # Run inference on video streams or files
â”‚   â”œâ”€â”€ model.py             # Model architecture
â”‚   â”œâ”€â”€ dataset.py           # Dataset loader utilities
â”‚   â”œâ”€â”€ helper.py            # Helper functions and metrics
â”‚   â””â”€â”€ config.py            # Configuration builder
â”‚
â”œâ”€â”€ data/                    # Raw and processed data
â”œâ”€â”€ checkpoints/             # Saved model weights
â”œâ”€â”€ outputs/                 # Evaluation results, ONNX models, etc.
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

````

---

## âš™ï¸ Setup

### 1ï¸âƒ£ Create Environment
```bash
python -m venv vadl-env
source vadl-env/bin/activate   # (Linux/Mac)
vadl-env\Scripts\activate      # (Windows)
````

### 2ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸš€ Running the Project

Follow these steps **in order** to fully execute the VADL pipeline:

---

### ğŸ§© Step 1 â€” Preprocessing

Extract frames, normalize, and prepare datasets.

```bash
python src/preprocessing.py
```

This script will:

* Extract frames from input videos.
* Normalize and resize them.
* Split into training/validation/test sets.
* Save processed data under `data/processed/`.

---

### ğŸ§  Step 2 â€” Training

Train the anomaly detection model.

```bash
python src/train.py
```

This will:

* Load the preprocessed dataset.
* Initialize the model from `model.py`.
* Log metrics (accuracy, F1-score, loss) via Weights & Biases or local logs.
* Save the trained weights to `checkpoints/`.

---

### ğŸ“Š Step 3 â€” Evaluation

Evaluate the trained model on validation or test data.

```bash
python src/evaluate.py
```

Generates:

* Quantitative metrics (accuracy, F1, precision, recall).
* Visualization plots under `outputs/`.

---

### ğŸ”„ Step 4 â€” Convert to ONNX

Convert the PyTorch model to ONNX format for deployment or inference optimization.

```bash
python src/convertonnx.py
```

Output:

```
outputs/model_vadl.onnx
```

---

### ğŸ¯ Step 5 â€” Inference

Run inference on new video files or camera streams.

```bash
python src/infer.py
```

Example:

```bash
python src/infer.py --video path/to/test_video.mp4
```

Outputs:

* Frame-level anomaly scores.
* Optional visualization of detected anomalies (bounding boxes or heatmaps).
* Log file under `outputs/inference_results/`.

---

## ğŸ§  Key Features

* ğŸ” **Anomaly Detection:** Learns normal spatiotemporal patterns and detects unusual activity.
* ğŸ•µï¸ **Localization:** Highlights regions of anomalies in the video.
* âš¡ **ONNX Export:** Optimized model ready for real-time deployment.
* ğŸ“ˆ **Evaluation Metrics:** Includes F1, accuracy, and custom anomaly scoring.

---

## ğŸ§© Future Improvements

* Integrate real-time camera streaming with anomaly visualization.
* Add temporal consistency constraints for smoother detection.
* Implement multi-scale feature fusion for better localization accuracy.

---

## ğŸ§¾ Citation

If you use or refer to this project in your research, please cite:

```
@project{vadl2025,
  title={VADL: Video Anomaly Detection and Localization},
  author={Shreethar Raveenthar},
  year={2025},
  url={https://github.com/yourusername/VADL}
}
```

---

## ğŸ‘¨â€ğŸ’» Author

**Shreethar Raveenthar**
AI Researcher & Developer | Robotics & Deep Learning
ğŸ“§ [your.email@example.com](mailto:your.email@example.com)
ğŸŒ [GitHub Profile](https://github.com/yourusername)

---

## ğŸªª License

This project is released under the **MIT License**.

```

---

Would you like me to make a **version with collapsible sections** (for example, click-to-expand â€œSetupâ€ or â€œRunning the Projectâ€ on GitHub)? It makes long READMEs like this much cleaner.
```
